# -*- coding: utf-8 -*-
"""EHOAFinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19kdurB8C5dS0zK-HBvBAmbqLdnVDg2fz
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Path to Drive

# megan's path to files
m_path = '/content/drive/My Drive/Economic History of the Americas/Data/'

# jonas's path to files
j_path = '/content/drive/My Drive/ YOUR PATH HERE '

# dishti's path to files
d_path = data_path = '/content/drive/My Drive/ECON-277 /'

## NOTE: it would be beneficial for your paths to be the same (i.e. same folder names, same file names, etc)
# so that you only need to load in the data once. If you have different paths, you will each need to load in the files to work on them.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

### counties of interest ###

# variables for filters
state_codes = [43, 71, 49, 21, 13] # FL, CA, TX, IL, NY
state_names = ['FL', 'CA', 'TX', 'IL', 'NY']
county_codes = [250, 110, 570, 990, 370, 2010, 310, 810, 590, 470]
county_names = ['DADE', 'BROWARD', 'HILLSBOROUGH', 'PALM BEACH', 'LOS ANGELES', 'HARRIS', 'COOK', 'QUEENS', 'ORANGE', 'KINGS']

# counties with high cuban immigrant population (US Census Data, published by Pew Research Center https://www.statista.com/statistics/234931/us-cuban-population-by-county/):
  # 1. Miami-Dade, FL:
      # State code: 43
      # County code: 0250
  # 2. Broward, FL:
      # State code: 43
      # County code: 0110
  # 3. Hillsborough, FL
      # State code: 43
      # County code: 0570
  # 4. Palm Beach, FL
      # State code: 43
      # County code: 0990
  # 5. LA County, CA
      # State code: 71
      # County code: 0370

# counties with high general immigrant population (US Census Bureau, ACS Survey https://www.migrationpolicy.org/programs/data-hub/charts/us-immigrant-population-state-and-county):
  # 1. Harris County, TX
      # State code: 49
      # County code: 2010
  # 2. Cook County, IL
      # State code: 21
      # County code: 0310
  # 3. Queens, NY
      # State code: 13
      # County code: 0810
  # 4. Orange County, CA
      # State code: 71
      # County code: 0590
  # 5. Kings County, NY
      # State code: 13
      # County code: 0470

## IPUMS Census Data: Jonas and Dishti ##
 # load in the data
    # use pd.read_csv(path + 'file name.csv') to load in each census year. you should name each dataset with the year so you can keep track. there is an example of this in my code below

 # clean the data
    # we want to get rid of missing information. you can use the pd.dropna() function to get rid of missing data in our columns of interest. you can google the documentation to help you.

    # we also only want the states/counties we are interested in. see the cell below for that information. the variables for state and county code are ICPSR, so you should be able to use the same codes.

# merge the data
    # Google the pd.merge function to combine the datasets

# analyze the data
    # now, we want to calculate the number of people with cuban origin. find BPL (250) and HISPAN (3) variables in the codebook to see what you need to filter by. we want to end up with a column with the percent of people with cuban origin. look into the groupby and sum functions.

    # compute the % change over each 10 year period

# load in data
df = pd.read_csv(m_path+'countypres_2000-2020.csv')

# sort by state and county
dade = (df['county_name'] == 'MIAMI-DADE') & (df['state_po']=='FL')
bro = (df['county_name'] == 'BROWARD') & (df['state_po']=='FL')
hill = (df['county_name'] == 'HILLSBOROUGH') & (df['state_po']=='FL')
palm = (df['county_name'] == 'PALM BEACH') & (df['state_po']=='FL')
la = (df['county_name'] == 'LOS ANGELES') & (df['state_po']=='CA')
harr = (df['county_name'] == 'HARRIS') & (df['state_po']=='TX')
cook = (df['county_name'] == 'COOK') & (df['state_po']=='IL')
queens = (df['county_name'] == 'QUEENS') & (df['state_po']=='NY')
oran = (df['county_name'] == 'ORANGE') & (df['state_po']=='CA')
kings = (df['county_name'] == 'KINGS') & (df['state_po']=='NY')

#states_df = df[df['state_po'].isin(state_names)]
county_df = df[dade | bro | hill | palm | la | harr | cook | queens | oran | kings]

# calculate percent of total votes
county_df.loc[:, 'fracvotes'] = (county_df['candidatevotes']/county_df['totalvotes'])*100

county_df['county_name'].unique()
# plot
for county in ['MIAMI-DADE', 'BROWARD', 'HILLSBOROUGH', 'PALM BEACH', 'LOS ANGELES', 'HARRIS', 'COOK', 'QUEENS', 'ORANGE', 'KINGS']:
  fd = county_df[county_df['county_name'] == county]
  hehe = fd.groupby(['party', 'year']).sum('county_fips').reset_index()
  for x in ['DEMOCRAT', 'REPUBLICAN', 'GREEN', 'OTHER']:
    temp = hehe[hehe['party'] == x]
    plt.plot(temp['year'], temp['fracvotes'], label = x)
    plt.legend()
    plt.title(county)
  plt.figure()

# 100 encoded as democrat, 200 encoded as republican

## load in data ##
datasets = pd.DataFrame()
for x in ['74', '76', '78', '80', '82', '84', '86', '88', '90']:
  temp_df = pd.read_csv(m_path + '19'+ x +'.tsv', sep='\t')
  temp_df['Year'] = '19' + x
  datasets = datasets.append(temp_df)


datasets['Year'].unique()
## clean data ##
# convert all applicable columns to ints
datasets = datasets.astype({'V1':int, 'Year':int, 'V6':int, 'V8':int, 'V44':int, 'V2': str})

# rename relevant variables
datasets.rename(columns = {'V1':'State Code', 'V2':'County Code', 'V6':'D_Gov', 'V8':'R_Gov', 'V44':'Total_Gov'}, inplace=True)

# keep relevant variables
datasets = datasets[['State Code', 'County Code', 'D_Gov', 'R_Gov', 'Total_Gov', 'Year']]

# get rid of missing data
no_miss = datasets[(datasets['D_Gov'] > 0) & (datasets['R_Gov'] > 0) & (datasets['Total_Gov'] > 0)]

df = no_miss[no_miss['Year'] == 1984]

# sort by state and county
states_df = no_miss[no_miss['State Code'].isin(state_codes)]
county_df = states_df[states_df['County Code'].isin(county_names)]

# get rid of  missing values in vote columns (M = 9999999)
county_df = county_df[(county_df['D_Gov'] != 9999999) & (county_df['R_Gov'] != 9999999) & (county_df['Total_Gov'] != 9999999)]

# Calculate total democratic and republican votes for each year/state/county
sum_df = county_df.groupby(['Year', 'State Code', 'County Code']).sum()
sum_df.loc[:,'D_VOTE'] = sum_df['D_Gov']/sum_df['Total_Gov']*100           # calculate percent of democratc vote
sum_df.loc[:,'R_VOTE'] = sum_df['R_Gov']/sum_df['Total_Gov']*100           # calulate percent of republican vote